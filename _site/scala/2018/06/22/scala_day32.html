<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Scala day 32 (spark with HDFS)</title>
  <meta name="description" content="使用 SparkSession 的 read 可讀取目錄底下所有的 csv 資料，加上 option(“header”,”true”) 可濾掉 header，但缺點是無法知道哪些知道是在哪個 file 裡 spark.read.option(&quot;header&quot;,&quot;true&quot;).format(&quot;com.databri...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/scala/2018/06/22/scala_day32.html">
  <link rel="alternate" type="application/rss+xml" title="Daniel&#39;s Blog" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">Daniel&#39;s Blog</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
            <a class="page-link" href="/about/">About</a>
            
          
            
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Scala day 32 (spark with HDFS)</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-06-22T10:44:17+08:00" itemprop="datePublished">
        
        Jun 22, 2018
      </time>
      </p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h4 id="使用-sparksession-的-read">使用 SparkSession 的 read</h4>
<ul>
  <li>可讀取目錄底下所有的 csv 資料，加上 option(“header”,”true”) 可濾掉 header，但缺點是無法知道哪些知道是在哪個 file 裡
    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span><span class="s">"true"</span><span class="o">).</span><span class="n">format</span><span class="o">(</span><span class="s">"com.databricks.spark.cvs"</span><span class="o">).</span><span class="n">csv</span><span class="o">(</span><span class="n">csvDir</span><span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">(</span><span class="k">_</span><span class="o">))</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="使用-sparkcontext-的-wholetextfiles">使用 Sparkcontext 的 wholeTextFiles</h4>
<ul>
  <li>可取得 RDD[(String, String)] 的型態，第一個 String 放檔案絕對路徑，第二個 String 放檔案的資料
    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">wholeTextFiles</span><span class="o">(</span><span class="n">csvDir</span><span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">pairdata</span> <span class="k">=&gt;</span> <span class="n">println</span><span class="o">(</span><span class="n">pairdata</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="s">" **** "</span> <span class="o">+</span> <span class="n">pairdata</span><span class="o">.</span><span class="n">_2</span><span class="o">))</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="使用-filtermapdrop-及-fold-等操作">使用 filter、map、drop 及 fold 等操作</h4>
<ul>
  <li>filter 選擇檔案開頭為 C 的，透過 map 將第一個值轉成檔名，第二個值由於是 csv 資料先透過 split(“\n”)轉成 array，第一行是標題，所以 drop 掉，再透過 fold 將 (dataLine + tempElement + “\n”) 一直壘加到 dataLine(初始值為””)．
    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">cdata</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">wholeTextFiles</span><span class="o">(</span><span class="n">csvDir</span><span class="o">)</span>
<span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">lastIndexOf</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">split</span><span class="o">(</span><span class="s">"_"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">==</span> <span class="s">"C"</span><span class="o">)</span>
<span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">lastIndexOf</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">split</span><span class="o">(</span><span class="s">"[.]"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">,</span> <span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">"\n"</span><span class="o">).</span><span class="n">drop</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">fold</span><span class="o">(</span><span class="s">""</span><span class="o">)</span> <span class="o">{</span>
  <span class="o">(</span><span class="n">dataLine</span> <span class="o">,</span> <span class="n">tempElement</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">dataLine</span> <span class="o">+</span> <span class="n">tempElement</span> <span class="o">+</span> <span class="s">"\n"</span>
<span class="o">}))</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="透過-dataframe-的-write-將資料寫入-hdfs">透過 DataFrame 的 write 將資料寫入 HDFS</h4>
<ul>
  <li>由於 cdata 已經是屬於 RDD，如果沒有先 collect()，在透過 sc.parallelize 轉 DataFrame 會出錯．
這種方式寫檔會再以檔名為目錄下，產生很多小檔．而且資料大時先 collect 會有風險．
    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="n">cdata</span><span class="o">.</span><span class="n">collect</span><span class="o">().</span><span class="n">foreach</span><span class="o">(</span><span class="n">csvFile</span> <span class="k">=&gt;</span> <span class="o">{</span>
<span class="k">val</span> <span class="n">csvDataDF</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="n">csvFile</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">stripLineEnd</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">"\n"</span><span class="o">).</span><span class="n">toSeq</span><span class="o">).</span><span class="n">toDF</span><span class="o">()</span>
<span class="n">csvDataDF</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">mode</span><span class="o">(</span><span class="nc">SaveMode</span><span class="o">.</span><span class="nc">Append</span><span class="o">).</span><span class="n">csv</span><span class="o">(</span><span class="s">"hdfs://192.168.61.105/tmp/csvfiles/"</span> <span class="o">+</span> <span class="n">csvFile</span><span class="o">.</span><span class="n">_1</span><span class="o">)</span>
<span class="o">})</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="使用-hdfs-的-api-將資料寫入-hdfs">使用 HDFS 的 api 將資料寫入 HDFS</h4>
<ul>
  <li>對資料一直 append 寫檔，會根據檔名為一個檔案，對各檔案一直 append 資料．這邊要注意副本數的設定，我測試的環境複本數為 1，所以這邊不設定的話會出現 Under-Replicated Blocks 的問題．</li>
</ul>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cdata</span><span class="o">.</span><span class="n">collect</span><span class="o">().</span><span class="n">foreach</span><span class="o">(</span><span class="n">csvFile</span> <span class="k">=&gt;</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">mergeHDFSFilePath</span> <span class="k">=</span> <span class="s">"hdfs://192.168.61.105/tmp/csvfiles/"</span> <span class="o">+</span> <span class="n">csvFile</span><span class="o">.</span><span class="n">_1</span>
  <span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
  <span class="n">conf</span><span class="o">.</span><span class="n">setBoolean</span><span class="o">(</span><span class="s">"dfs.support.append"</span> <span class="o">,</span> <span class="kc">true</span><span class="o">)</span>
  <span class="n">conf</span><span class="o">.</span><span class="n">setInt</span><span class="o">(</span><span class="s">"dfs.replication"</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="c1">//會根據環境的副本數決定
</span>  <span class="c1">//conf.addResource(new Path("/Volumes/Transcend/1-program-workspace/2-intellij-workspace/streaming-test/config/hdfs-site.xml"))
</span>  <span class="k">val</span> <span class="n">fs</span> <span class="k">=</span> <span class="nc">FileSystem</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="nc">URI</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">mergeHDFSFilePath</span><span class="o">)</span> <span class="o">,</span> <span class="n">conf</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">hdfsPath</span> <span class="k">=</span> <span class="k">new</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="nc">Path</span><span class="o">(</span><span class="n">mergeHDFSFilePath</span><span class="o">)</span>
  <span class="k">val</span> <span class="n">out</span> <span class="k">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">exists</span><span class="o">(</span><span class="n">hdfsPath</span><span class="o">)</span> <span class="k">match</span> <span class="o">{</span>
    <span class="k">case</span> <span class="kc">true</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">BufferedWriter</span><span class="o">(</span><span class="k">new</span> <span class="nc">OutputStreamWriter</span><span class="o">(</span><span class="n">fs</span><span class="o">.</span><span class="n">append</span><span class="o">(</span><span class="n">hdfsPath</span><span class="o">)))</span>
    <span class="k">case</span> <span class="kc">false</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">BufferedWriter</span><span class="o">(</span><span class="k">new</span> <span class="nc">OutputStreamWriter</span><span class="o">(</span><span class="n">fs</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">hdfsPath</span><span class="o">)))</span>
  <span class="o">}</span>
  <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="o">(</span><span class="n">csvFile</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
  <span class="n">out</span><span class="o">.</span><span class="n">flush</span><span class="o">()</span>
<span class="o">})</span>
</code></pre></div></div>

<h4 id="databeantestscala">DataBeanTest.scala</h4>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">java.io.</span><span class="o">{</span><span class="nc">BufferedWriter</span><span class="o">,</span> <span class="nc">OutputStreamWriter</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">java.net.URI</span>

<span class="k">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span>
<span class="k">import</span> <span class="nn">org.apache.hadoop.fs.FileSystem</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.</span><span class="o">{</span><span class="nc">SaveMode</span><span class="o">,</span> <span class="nc">SparkSession</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span>
<span class="k">import</span> <span class="nn">org.scalatest.FunSuite</span>

<span class="k">class</span> <span class="nc">DataBeanTest</span> <span class="k">extends</span> <span class="nc">FunSuite</span> <span class="o">{</span>

  <span class="n">test</span><span class="o">(</span><span class="s">"read Data"</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">userSchema</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StructType</span><span class="o">()</span>
      <span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="s">"TagName"</span><span class="o">,</span> <span class="s">"string"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="s">"TimeStamp"</span><span class="o">,</span> <span class="s">"string"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="s">"Min"</span><span class="o">,</span> <span class="s">"integer"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="s">"Max"</span><span class="o">,</span> <span class="s">"integer"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="s">"Avg"</span><span class="o">,</span> <span class="s">"double"</span><span class="o">)</span>

    <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
      <span class="o">.</span><span class="n">builder</span>
      <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">"Spark-csv"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">"local[2]"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>

    <span class="k">val</span> <span class="n">csvDir</span> <span class="k">=</span> <span class="s">"/Volumes/Transcend/1-program-workspace/2-intellij-workspace/streaming-test/csvfile"</span>
    <span class="cm">/*
    val csvDF = spark.read
      .option("header","true")
      .schema(userSchema)
      .csv("/Volumes/Transcend/1-program-workspace/2-intellij-workspace/streaming-test/csvfile")
    */</span>
      <span class="c1">//df.coalesce(1).write.format("com.databricks.spark.cvs").save("...path...")
</span>    <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span><span class="s">"true"</span><span class="o">).</span><span class="n">format</span><span class="o">(</span><span class="s">"com.databricks.spark.cvs"</span><span class="o">).</span><span class="n">csv</span><span class="o">(</span><span class="n">csvDir</span><span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">(</span><span class="k">_</span><span class="o">))</span>
  <span class="o">}</span>

  <span class="n">test</span><span class="o">(</span><span class="s">"use wholeTextFiles"</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
      <span class="o">.</span><span class="n">builder</span>
      <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">"Spark-csv"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">"local[2]"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
    <span class="k">val</span> <span class="n">csvDir</span> <span class="k">=</span> <span class="s">"/Volumes/Transcend/1-program-workspace/2-intellij-workspace/streaming-test/csvfile"</span>
    <span class="c1">//(filePath , fileData)
</span>    <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">wholeTextFiles</span><span class="o">(</span><span class="n">csvDir</span><span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">pairdata</span> <span class="k">=&gt;</span> <span class="n">println</span><span class="o">(</span><span class="n">pairdata</span><span class="o">.</span><span class="n">_1</span> <span class="o">+</span> <span class="s">" **** "</span> <span class="o">+</span> <span class="n">pairdata</span><span class="o">.</span><span class="n">_2</span><span class="o">))</span>
  <span class="o">}</span>

  <span class="n">test</span><span class="o">(</span><span class="s">"read wholeTextFiles get fileName"</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
      <span class="o">.</span><span class="n">builder</span>
      <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">"Spark-csv"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">"local[2]"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
    <span class="k">val</span> <span class="n">csvDir</span> <span class="k">=</span> <span class="s">"/Volumes/Transcend/1-program-workspace/2-intellij-workspace/streaming-test/csvfile"</span>

    <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">wholeTextFiles</span><span class="o">(</span><span class="n">csvDir</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">lastIndexOf</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">split</span><span class="o">(</span><span class="s">"_"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)).</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">(</span><span class="k">_</span><span class="o">))</span>
  <span class="o">}</span>

  <span class="n">test</span><span class="o">(</span><span class="s">"read wholeTextFiles filter fileName"</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
      <span class="o">.</span><span class="n">builder</span>
      <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">"Spark-csv"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">"local[2]"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
    <span class="k">val</span> <span class="n">csvDir</span> <span class="k">=</span> <span class="s">"/Volumes/Transcend/1-program-workspace/2-intellij-workspace/streaming-test/csvfile"</span>

    <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">wholeTextFiles</span><span class="o">(</span><span class="n">csvDir</span><span class="o">).</span><span class="n">filter</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">lastIndexOf</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">split</span><span class="o">(</span><span class="s">"_"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">==</span> <span class="s">"C"</span><span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">(</span><span class="k">_</span><span class="o">))</span>
  <span class="o">}</span>

  <span class="n">test</span><span class="o">(</span><span class="s">"remove csv string header"</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="s">"TagName,TimeStamp,Min,Max,Avg\nL41-F200A-HH,2018-05-09 10:18:25,0,0,0\nL41-F200A-HK,2018-05-10 11:18:25,0,0,0"</span>
    <span class="k">val</span> <span class="n">line</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">"\n"</span><span class="o">).</span><span class="n">drop</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">fold</span><span class="o">(</span><span class="s">""</span><span class="o">)</span> <span class="o">{</span>
      <span class="o">(</span><span class="n">dataLine</span> <span class="o">,</span> <span class="n">tempElement</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">dataLine</span> <span class="o">+</span> <span class="n">tempElement</span> <span class="o">+</span> <span class="s">"\n"</span>
    <span class="o">}</span>
    <span class="n">println</span><span class="o">(</span><span class="n">line</span><span class="o">)</span>
  <span class="o">}</span>

  <span class="n">test</span><span class="o">(</span><span class="s">"onlyGetCaculateData"</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
      <span class="o">.</span><span class="n">builder</span>
      <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">"Spark-csv"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">"local[2]"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
    <span class="k">val</span> <span class="n">csvDir</span> <span class="k">=</span> <span class="s">"/Volumes/Transcend/1-program-workspace/2-intellij-workspace/streaming-test/csvfile"</span>

    <span class="k">val</span> <span class="n">cdata</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">wholeTextFiles</span><span class="o">(</span><span class="n">csvDir</span><span class="o">)</span>
      <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">lastIndexOf</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">split</span><span class="o">(</span><span class="s">"_"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">==</span> <span class="s">"C"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">lastIndexOf</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">split</span><span class="o">(</span><span class="s">"[.]"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">,</span> <span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">"\n"</span><span class="o">).</span><span class="n">drop</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">fold</span><span class="o">(</span><span class="s">""</span><span class="o">)</span> <span class="o">{</span>
        <span class="o">(</span><span class="n">dataLine</span> <span class="o">,</span> <span class="n">tempElement</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">dataLine</span> <span class="o">+</span> <span class="n">tempElement</span> <span class="o">+</span> <span class="s">"\n"</span>
      <span class="o">}))</span>
    <span class="n">cdata</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">(</span><span class="k">_</span><span class="o">))</span>
  <span class="o">}</span>

  <span class="n">test</span><span class="o">(</span><span class="s">"getCdataToHdfs_1"</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
      <span class="o">.</span><span class="n">builder</span>
      <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">"Spark-csv"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">"local[4]"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
    <span class="k">val</span> <span class="n">csvDir</span> <span class="k">=</span> <span class="s">"/Volumes/Transcend/1-program-workspace/2-intellij-workspace/streaming-test/csvfile"</span>
    <span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>

    <span class="k">val</span> <span class="n">cdata</span><span class="k">:</span><span class="kt">RDD</span><span class="o">[</span><span class="kt">Tuple2</span><span class="o">[</span><span class="kt">String</span>,<span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">wholeTextFiles</span><span class="o">(</span><span class="n">csvDir</span><span class="o">)</span>
      <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">lastIndexOf</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">split</span><span class="o">(</span><span class="s">"_"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">==</span> <span class="s">"C"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">lastIndexOf</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">split</span><span class="o">(</span><span class="s">"[.]"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">,</span> <span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">"\n"</span><span class="o">).</span><span class="n">drop</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">fold</span><span class="o">(</span><span class="s">""</span><span class="o">)</span> <span class="o">{</span>
        <span class="o">(</span><span class="n">dataLine</span> <span class="o">,</span> <span class="n">tempElement</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">dataLine</span> <span class="o">+</span> <span class="n">tempElement</span> <span class="o">+</span> <span class="s">"\n"</span>
      <span class="o">}))</span>

    <span class="k">import</span> <span class="nn">spark.implicits._</span>
    <span class="n">cdata</span><span class="o">.</span><span class="n">collect</span><span class="o">().</span><span class="n">foreach</span><span class="o">(</span><span class="n">csvFile</span> <span class="k">=&gt;</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">csvDataDF</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="n">csvFile</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">stripLineEnd</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">"\n"</span><span class="o">).</span><span class="n">toSeq</span><span class="o">).</span><span class="n">toDF</span><span class="o">()</span>
      <span class="n">csvDataDF</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">mode</span><span class="o">(</span><span class="nc">SaveMode</span><span class="o">.</span><span class="nc">Append</span><span class="o">).</span><span class="n">csv</span><span class="o">(</span><span class="s">"hdfs://192.168.61.105/tmp/csvfiles/"</span> <span class="o">+</span> <span class="n">csvFile</span><span class="o">.</span><span class="n">_1</span><span class="o">)</span>
    <span class="o">})</span>
  <span class="o">}</span>

  <span class="n">test</span><span class="o">(</span><span class="s">"getCdataToHdfs_2"</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
      <span class="o">.</span><span class="n">builder</span>
      <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">"Spark-csv"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">"local[4]"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
    <span class="k">val</span> <span class="n">csvDir</span> <span class="k">=</span> <span class="s">"/Volumes/Transcend/1-program-workspace/2-intellij-workspace/streaming-test/csvfile"</span>
    <span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>
    <span class="k">val</span> <span class="n">cdata</span><span class="k">:</span><span class="kt">RDD</span><span class="o">[</span><span class="kt">Tuple2</span><span class="o">[</span><span class="kt">String</span>,<span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">wholeTextFiles</span><span class="o">(</span><span class="n">csvDir</span><span class="o">)</span>
      <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">lastIndexOf</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">split</span><span class="o">(</span><span class="s">"_"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">==</span> <span class="s">"C"</span><span class="o">)</span>
      <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">substring</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">_1</span><span class="o">.</span><span class="n">lastIndexOf</span><span class="o">(</span><span class="s">"/"</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">split</span><span class="o">(</span><span class="s">"[.]"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">,</span> <span class="n">x</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">"\n"</span><span class="o">).</span><span class="n">drop</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">fold</span><span class="o">(</span><span class="s">""</span><span class="o">)</span> <span class="o">{</span>
        <span class="o">(</span><span class="n">dataLine</span> <span class="o">,</span> <span class="n">tempElement</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">dataLine</span> <span class="o">+</span> <span class="n">tempElement</span> <span class="o">+</span> <span class="s">"\n"</span>
      <span class="o">}))</span>

    <span class="n">cdata</span><span class="o">.</span><span class="n">collect</span><span class="o">().</span><span class="n">foreach</span><span class="o">(</span><span class="n">csvFile</span> <span class="k">=&gt;</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">mergeHDFSFilePath</span> <span class="k">=</span> <span class="s">"hdfs://192.168.61.105/tmp/csvfiles/"</span> <span class="o">+</span> <span class="n">csvFile</span><span class="o">.</span><span class="n">_1</span>
      <span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
      <span class="n">conf</span><span class="o">.</span><span class="n">setBoolean</span><span class="o">(</span><span class="s">"dfs.support.append"</span> <span class="o">,</span> <span class="kc">true</span><span class="o">)</span>
      <span class="n">conf</span><span class="o">.</span><span class="n">setInt</span><span class="o">(</span><span class="s">"dfs.replication"</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="c1">//會根據環境的副本數決定
</span>      <span class="c1">//conf.addResource(new Path("/Volumes/Transcend/1-program-workspace/2-intellij-workspace/streaming-test/config/hdfs-site.xml"))
</span>      <span class="k">val</span> <span class="n">fs</span> <span class="k">=</span> <span class="nc">FileSystem</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="nc">URI</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">mergeHDFSFilePath</span><span class="o">)</span> <span class="o">,</span> <span class="n">conf</span><span class="o">)</span>
      <span class="k">val</span> <span class="n">hdfsPath</span> <span class="k">=</span> <span class="k">new</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="nc">Path</span><span class="o">(</span><span class="n">mergeHDFSFilePath</span><span class="o">)</span>
      <span class="k">val</span> <span class="n">out</span> <span class="k">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">exists</span><span class="o">(</span><span class="n">hdfsPath</span><span class="o">)</span> <span class="k">match</span> <span class="o">{</span>
        <span class="k">case</span> <span class="kc">true</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">BufferedWriter</span><span class="o">(</span><span class="k">new</span> <span class="nc">OutputStreamWriter</span><span class="o">(</span><span class="n">fs</span><span class="o">.</span><span class="n">append</span><span class="o">(</span><span class="n">hdfsPath</span><span class="o">)))</span>
        <span class="k">case</span> <span class="kc">false</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">BufferedWriter</span><span class="o">(</span><span class="k">new</span> <span class="nc">OutputStreamWriter</span><span class="o">(</span><span class="n">fs</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">hdfsPath</span><span class="o">)))</span>
      <span class="o">}</span>
      <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="o">(</span><span class="n">csvFile</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
      <span class="n">out</span><span class="o">.</span><span class="n">flush</span><span class="o">()</span>
    <span class="o">})</span>
  <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div>

<ul>
  <li>原本使用 hdfs api 操作如果 receiveRdd 不下 collect，會出現 task not serialize．
換個方式 receiveRdd 使用 foreachPartition 之後就可以了．</li>
</ul>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">package</span> <span class="nn">com.fareast.scala.streaming.job</span>

<span class="k">import</span> <span class="nn">java.io.</span><span class="o">{</span><span class="nc">BufferedWriter</span><span class="o">,</span> <span class="nc">OutputStreamWriter</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">java.net.URI</span>
<span class="k">import</span> <span class="nn">java.util.Properties</span>

<span class="k">import</span> <span class="nn">com.fareast.scala.bean.UserBean</span>
<span class="k">import</span> <span class="nn">com.fareast.scala.receivers.FtpFileReadReceiver</span>
<span class="k">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span>
<span class="k">import</span> <span class="nn">org.apache.hadoop.fs.FileSystem</span>
<span class="k">import</span> <span class="nn">org.apache.spark.SparkConf</span>
<span class="k">import</span> <span class="nn">org.apache.spark.streaming.</span><span class="o">{</span><span class="nc">Seconds</span><span class="o">,</span> <span class="nc">StreamingContext</span><span class="o">}</span>

<span class="k">object</span> <span class="nc">FTPReadStreamingJob</span> <span class="o">{</span>

  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">reader</span> <span class="k">=</span> <span class="n">scala</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="nc">Source</span><span class="o">.</span><span class="n">fromURL</span><span class="o">(</span><span class="n">getClass</span><span class="o">.</span><span class="n">getResource</span><span class="o">(</span><span class="s">"/config.properties"</span><span class="o">)).</span><span class="n">bufferedReader</span><span class="o">()</span>
    <span class="k">val</span> <span class="n">prop</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">()</span>
    <span class="n">prop</span><span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="n">reader</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">ftpUsername</span> <span class="k">=</span> <span class="n">prop</span><span class="o">.</span><span class="n">getProperty</span><span class="o">(</span><span class="s">"ftp.username"</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">ftpPassword</span> <span class="k">=</span> <span class="n">prop</span><span class="o">.</span><span class="n">getProperty</span><span class="o">(</span><span class="s">"ftp.password"</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">ftpHost</span> <span class="k">=</span> <span class="n">prop</span><span class="o">.</span><span class="n">getProperty</span><span class="o">(</span><span class="s">"ftp.host"</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">ftpInpath</span> <span class="k">=</span> <span class="n">prop</span><span class="o">.</span><span class="n">getProperty</span><span class="o">(</span><span class="s">"ftp.inPath"</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">ftpOutpath</span> <span class="k">=</span> <span class="n">prop</span><span class="o">.</span><span class="n">getProperty</span><span class="o">(</span><span class="s">"ftp.outPath"</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">hdfsOutpath</span> <span class="k">=</span> <span class="n">prop</span><span class="o">.</span><span class="n">getProperty</span><span class="o">(</span><span class="s">"hdfs.outPath"</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">xlsxConfigPath</span> <span class="k">=</span> <span class="n">prop</span><span class="o">.</span><span class="n">getProperty</span><span class="o">(</span><span class="s">"xlsx.configPath"</span><span class="o">)</span>


    <span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">().</span><span class="n">setMaster</span><span class="o">(</span><span class="s">"local[2]"</span><span class="o">).</span><span class="n">setAppName</span><span class="o">(</span><span class="s">"FileWordCount"</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">ssc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StreamingContext</span><span class="o">(</span><span class="n">conf</span><span class="o">,</span> <span class="nc">Seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
    <span class="k">val</span> <span class="n">ftpUser</span> <span class="k">=</span> <span class="nc">UserBean</span><span class="o">(</span><span class="n">ftpUsername</span><span class="o">,</span><span class="n">ftpPassword</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">receiveRdds</span> <span class="k">=</span> <span class="n">ssc</span><span class="o">.</span><span class="n">receiverStream</span><span class="o">(</span><span class="k">new</span> <span class="nc">FtpFileReadReceiver</span><span class="o">(</span><span class="n">ftpUser</span><span class="o">,</span><span class="n">ftpHost</span><span class="o">,</span><span class="n">ftpInpath</span><span class="o">,</span><span class="n">ftpOutpath</span><span class="o">))</span>

    <span class="n">receiveRdds</span><span class="o">.</span><span class="n">foreachRDD</span><span class="o">(</span><span class="n">receiveRdd</span> <span class="k">=&gt;</span> <span class="n">receiveRdd</span><span class="o">.</span><span class="n">groupByKey</span><span class="o">().</span><span class="n">foreachPartition</span><span class="o">(</span><span class="n">receiveFileInfo</span> <span class="k">=&gt;</span> <span class="o">{</span>
      <span class="n">receiveFileInfo</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">receiveFile</span> <span class="k">=&gt;</span> <span class="o">{</span>
        <span class="k">val</span> <span class="n">hdfsConf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
        <span class="n">hdfsConf</span><span class="o">.</span><span class="n">setBoolean</span><span class="o">(</span><span class="s">"dfs.support.append"</span> <span class="o">,</span> <span class="kc">true</span><span class="o">)</span>
        <span class="n">hdfsConf</span><span class="o">.</span><span class="n">setInt</span><span class="o">(</span><span class="s">"dfs.replication"</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span>
        <span class="k">val</span> <span class="n">fileName</span> <span class="k">=</span> <span class="n">receiveFile</span><span class="o">.</span><span class="n">_1</span>
        <span class="k">if</span><span class="o">(</span><span class="n">fileName</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">"_"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">==</span> <span class="s">"C"</span><span class="o">)</span> <span class="o">{</span>
          <span class="k">val</span> <span class="n">mergeHDFSFilePath</span> <span class="k">=</span> <span class="s">"hdfs://"</span> <span class="o">+</span> <span class="n">hdfsOutpath</span> <span class="o">+</span> <span class="s">"/caculatedata/"</span> <span class="o">+</span> <span class="n">fileName</span>
          <span class="k">val</span> <span class="n">out</span> <span class="k">=</span> <span class="n">getOutput</span><span class="o">(</span><span class="n">mergeHDFSFilePath</span><span class="o">)</span>

          <span class="k">var</span> <span class="n">isHead</span> <span class="k">=</span> <span class="kc">true</span>
          <span class="k">val</span> <span class="n">fileDatas</span> <span class="k">=</span> <span class="n">receiveFile</span><span class="o">.</span><span class="n">_2</span>
          <span class="n">fileDatas</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span>
            <span class="n">fileData</span> <span class="k">=&gt;</span> <span class="o">{</span>
              <span class="k">if</span><span class="o">(!</span><span class="n">isHead</span><span class="o">)</span> <span class="o">{</span>
                <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="o">(</span><span class="n">fileData</span><span class="o">)</span>
                <span class="n">out</span><span class="o">.</span><span class="n">newLine</span><span class="o">()</span>
                <span class="n">out</span><span class="o">.</span><span class="n">flush</span><span class="o">()</span>
              <span class="o">}</span>
              <span class="n">isHead</span> <span class="k">=</span> <span class="kc">false</span>
            <span class="o">}</span>
          <span class="o">)</span>
          <span class="n">out</span><span class="o">.</span><span class="n">close</span><span class="o">()</span>
          <span class="c1">//fs.close()
</span>        <span class="o">}</span> <span class="k">else</span> <span class="k">if</span><span class="o">(</span><span class="n">fileName</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">"_"</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="o">==</span> <span class="s">"R"</span><span class="o">)</span> <span class="o">{</span>
          <span class="k">val</span> <span class="n">mergeHDFSFilePath</span> <span class="k">=</span> <span class="s">"hdfs://"</span> <span class="o">+</span> <span class="n">hdfsOutpath</span> <span class="o">+</span> <span class="s">"/rowdata/"</span> <span class="o">+</span> <span class="n">fileName</span>
          <span class="k">val</span> <span class="n">out</span> <span class="k">=</span> <span class="n">getOutput</span><span class="o">(</span><span class="n">mergeHDFSFilePath</span><span class="o">)</span>
          <span class="k">val</span> <span class="n">fileDatas</span> <span class="k">=</span> <span class="n">receiveFile</span><span class="o">.</span><span class="n">_2</span>
          <span class="k">var</span> <span class="n">isHead</span> <span class="k">=</span> <span class="kc">true</span>
          <span class="n">fileDatas</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span>
            <span class="n">fileData</span> <span class="k">=&gt;</span> <span class="o">{</span>
              <span class="k">if</span><span class="o">(!</span><span class="n">isHead</span><span class="o">)</span> <span class="o">{</span>
                <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="o">(</span><span class="n">fileData</span><span class="o">)</span>
                <span class="n">out</span><span class="o">.</span><span class="n">newLine</span><span class="o">()</span>
                <span class="n">out</span><span class="o">.</span><span class="n">flush</span><span class="o">()</span>
              <span class="o">}</span>
              <span class="n">isHead</span> <span class="k">=</span> <span class="kc">false</span>
            <span class="o">}</span>
          <span class="o">)</span>
          <span class="n">out</span><span class="o">.</span><span class="n">close</span><span class="o">()</span>
          <span class="c1">//fs.close()
</span>        <span class="o">}</span>
        <span class="n">println</span><span class="o">(</span><span class="s">"========== fileName : "</span> <span class="o">+</span> <span class="n">fileName</span> <span class="o">+</span> <span class="s">" END =========="</span><span class="o">)</span>
      <span class="o">})</span>
    <span class="o">}))</span>

<span class="cm">/*
    receiveRdds.foreachRDD(receiveRdd =&gt; receiveRdd.groupByKey.collect.foreach(receiveFile =&gt; {
      val hdfsConf = new Configuration()
      hdfsConf.setBoolean("dfs.support.append" , true)
      hdfsConf.setInt("dfs.replication", 1)

      val fileName = receiveFile._1
      if(fileName.split("_")(0) == "C") {
        val mergeHDFSFilePath = "hdfs://" + hdfsOutpath + "/caculatedata/" + fileName
        val out = getOutput(mergeHDFSFilePath)

        var isHead = true
        val fileDatas = receiveFile._2
        fileDatas.foreach(
          fileData =&gt; {
            if(!isHead) {
              out.write(fileData)
              out.newLine()
              out.flush()
            }
            isHead = false
          }
        )
        out.close()
        //fs.close()
      } else if(fileName.split("_")(0) == "R") {
        val mergeHDFSFilePath = "hdfs://" + hdfsOutpath + "/rowdata/" + fileName
        val out = getOutput(mergeHDFSFilePath)
        val fileDatas = receiveFile._2
        var isHead = true
        fileDatas.foreach(
          fileData =&gt; {
            if(!isHead) {
              out.write(fileData)
              out.newLine()
              out.flush()
            }
            isHead = false
          }
        )
        out.close()
        //fs.close()
      }
      println("========== fileName : " + fileName + " END ==========")
    }))
*/</span>

    <span class="cm">/*
    receiveRdds.foreachRDD(receiveRdd =&gt; {
      if(receiveRdd != null) {
        if(!receiveRdd.isEmpty()) {
          val fileName = receiveRdd.first()._1
          val fileData = receiveRdd.map(data =&gt; data._2)
          //println("#### fileName ---&gt; " + fileName)
          //println("#### fileData ---&gt; " + fileData)

          if(fileName.split("_")(0) == "C") {
            fileData.saveAsTextFile("hdfs://" + hdfsPath + "/caculatedata/" + fileName)
          } else if(fileName.split("_")(0) == "R") {
            fileData.saveAsTextFile("hdfs://" + hdfsPath + "/rowdata/" + fileName)
          }
        }
      }
    })
    */</span>
    <span class="n">ssc</span><span class="o">.</span><span class="n">start</span><span class="o">()</span>
    <span class="n">ssc</span><span class="o">.</span><span class="n">awaitTermination</span><span class="o">()</span>
  <span class="o">}</span>

  <span class="k">def</span> <span class="n">getOutput</span><span class="o">(</span><span class="n">mergeHDFSFilePath</span><span class="k">:</span><span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">BufferedWriter</span> <span class="o">=</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">hdfsConf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
    <span class="n">hdfsConf</span><span class="o">.</span><span class="n">setBoolean</span><span class="o">(</span><span class="s">"dfs.support.append"</span> <span class="o">,</span> <span class="kc">true</span><span class="o">)</span>
    <span class="n">hdfsConf</span><span class="o">.</span><span class="n">setInt</span><span class="o">(</span><span class="s">"dfs.replication"</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">fs</span> <span class="k">=</span> <span class="nc">FileSystem</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="nc">URI</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">mergeHDFSFilePath</span><span class="o">)</span> <span class="o">,</span> <span class="n">hdfsConf</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">mergehdfsPath</span> <span class="k">=</span> <span class="k">new</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="nc">Path</span><span class="o">(</span><span class="n">mergeHDFSFilePath</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">out</span> <span class="k">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">exists</span><span class="o">(</span><span class="n">mergehdfsPath</span><span class="o">)</span> <span class="k">match</span> <span class="o">{</span>
      <span class="k">case</span> <span class="kc">true</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">BufferedWriter</span><span class="o">(</span><span class="k">new</span> <span class="nc">OutputStreamWriter</span><span class="o">(</span><span class="n">fs</span><span class="o">.</span><span class="n">append</span><span class="o">(</span><span class="n">mergehdfsPath</span><span class="o">)))</span>
      <span class="k">case</span> <span class="kc">false</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">BufferedWriter</span><span class="o">(</span><span class="k">new</span> <span class="nc">OutputStreamWriter</span><span class="o">(</span><span class="n">fs</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="n">mergehdfsPath</span><span class="o">)))</span>
    <span class="o">}</span>
    <span class="n">out</span>
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

  </div>

  

  <a class="u-url" href="/scala/2018/06/22/scala_day32.html" hidden></a>
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Daniel&#39;s Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Daniel&#39;s Blog
            
            </li>
            
            <li><a href="mailto:your-email@example.com">your-email@example.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/jekyll"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">jekyll</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/jekyllrb"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">jekyllrb</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
